{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eligibility for mobilization: Cohort identification. \n",
    "\n",
    "This script identifies the cohort using CLIF 2.0 tables. \n",
    "\n",
    "Requirements:\n",
    "* Required table filenames should be clif_patient, clif_hospitalization, clif_adt, clif_vitals, clif_labs, clif_medication_admin_continuous, clif_respiratory_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from config.json\n",
      "{'site_name': 'UCMC', 'tables_path': '/Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19', 'file_type': 'parquet'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import pyCLIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kavenchhikara/Desktop/CLIF/CLIF-eligibility-for-mobilization/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the output should be the location of this file\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from config.json\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from utils import config\n",
    "# Load the configuration\n",
    "config = config.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site Name: UCMC\n",
      "Tables Path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19\n",
      "Output path: ../output/final\n",
      "File Type: parquet\n"
     ]
    }
   ],
   "source": [
    "# Access configuration parameters\n",
    "site_name = config['site_name']\n",
    "tables_path = config['tables_path']\n",
    "file_type = config['file_type']\n",
    "output_path = os.path.join(\"..\", \"output\", \"final\")\n",
    "\n",
    "# Make sure the directory exists; if not, create it\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Print the configuration parameters\n",
    "print(f\"Site Name: {site_name}\")\n",
    "print(f\"Tables Path: {tables_path}\")\n",
    "print(f\"Output path: {output_path}\")\n",
    "print(f\"File Type: {file_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confirm that these are the correct paths\n",
    "patient_filepath                 = f\"{tables_path}/clif_patient.{file_type}\"\n",
    "hospitalization_filepath         = f\"{tables_path}/clif_hospitalization.{file_type}\"\n",
    "adt_filepath                     = f\"{tables_path}/clif_adt.{file_type}\"\n",
    "vitals_filepath                  = f\"{tables_path}/rclif/clif_vitals.{file_type}\"\n",
    "labs_filepath                    = f\"{tables_path}/rclif/clif_labs.{file_type}\"\n",
    "meds_filepath                    = f\"{tables_path}/rclif/clif_medication_admin_continuous.{file_type}\"\n",
    "resp_support_filepath            = f\"{tables_path}/rclif/clif_respiratory_support.{file_type}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, file_type):\n",
    "    \"\"\"\n",
    "    Read data from file based on file type.\n",
    "    Parameters:\n",
    "        filepath (str): Path to the file.\n",
    "        file_type (str): Type of the file ('csv' or 'parquet').\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Record the start time\n",
    "    file_name = os.path.basename(filepath) \n",
    "    if file_type == 'csv':\n",
    "        df = pd.read_csv(filepath)\n",
    "    elif file_type == 'parquet':\n",
    "        table = pq.read_table(filepath)\n",
    "        df = table.to_pandas()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please provide either 'csv' or 'parquet'.\")\n",
    "    \n",
    "    end_time = time.time()  # Record the end time\n",
    "    load_time = end_time - start_time  # Calculate the loading time\n",
    "    \n",
    "    # Calculate the size of the loaded dataset in MB\n",
    "    dataset_size_mb = df.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "    print(f\"File name: {file_name}\")\n",
    "    print(f\"Time taken to load the dataset: {load_time:.2f} seconds\")\n",
    "    print(f\"Size of the loaded dataset: {dataset_size_mb:.2f} MB\\n\")\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def count_unique_encounters(df, encounter_column='encounter_id'):\n",
    "    \"\"\"\n",
    "    Counts the unique encounters in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to analyze.\n",
    "    encounter_column (str): The name of the column containing encounter IDs (default is 'encounter_id').\n",
    "    \n",
    "    Returns:\n",
    "    int: The number of unique encounters.\n",
    "    \"\"\"\n",
    "    return df[encounter_column].nunique()\n",
    "\n",
    "\n",
    "def generate_facetgrid_histograms(data, category_column, value_column):\n",
    "    \"\"\"\n",
    "    Generate histograms using seaborn's FacetGrid.\n",
    "\n",
    "    Parameters:\n",
    "        data (DataFrame): DataFrame containing the data.\n",
    "        category_column (str): Name of the column containing categories.\n",
    "        value_column (str): Name of the column containing values.\n",
    "\n",
    "    Returns:\n",
    "        FacetGrid: Seaborn FacetGrid object containing the generated histograms.\n",
    "    \"\"\"\n",
    "    # Create a FacetGrid\n",
    "    g = sns.FacetGrid(data, col=category_column, col_wrap=6, sharex=False, sharey=False)\n",
    "    g.map(sns.histplot, value_column, bins=30, color='blue', edgecolor='black')\n",
    "\n",
    "    # Set titles and labels\n",
    "    g.set_titles('{col_name}')\n",
    "    g.set_axis_labels(value_column, 'Frequency')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(f'Histograms of {value_column} by {category_column}', fontsize=16)\n",
    "\n",
    "    return g\n",
    "\n",
    "def standardize_datetime(df):\n",
    "    \"\"\"\n",
    "    Ensure that all *_dttm variables are in the correct format.\n",
    "    Convert all datetime columns to a specific precision and remove timezone\n",
    "    Parameters:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    Returns:\n",
    "        DataFrame: DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Here converting to 'datetime64[ns]' for uniformity and removing timezone with 'tz_convert(None)'\n",
    "            df[col] = df[col].dt.tz_convert(None) if df[col].dt.tz is not None else df[col]\n",
    "            # If you need to standardize to UTC and keep the timezone:\n",
    "            # df[col] = df[col].dt.tz_localize('UTC') if df[col].dt.tz is None else df[col].dt.tz_convert('UTC')\n",
    "    return df\n",
    "\n",
    "def get_sql_import(file_type):\n",
    "    if file_type == 'parquet':\n",
    "        return 'read_parquet'\n",
    "    if file_type == 'csv':\n",
    "        return 'read_csv_auto'\n",
    "\n",
    "sql_import = get_sql_import(file_type=file_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_patient.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_patient.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_hospitalization.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_hospitalization.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_adt.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_adt.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_vitals.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_vitals.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_labs.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_labs.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_medication_admin_continuous.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_medication_admin_continuous.parquet\n",
      "Table final path: /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_respiratory_support.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_respiratory_support.parquet\n"
     ]
    }
   ],
   "source": [
    "patient = pyCLIF.load_data('clif_patient')\n",
    "hospitalization = pyCLIF.load_data('clif_hospitalization')\n",
    "adt = pyCLIF.load_data('clif_adt')\n",
    "vitals = pyCLIF.load_data('clif_vitals')\n",
    "labs = pyCLIF.load_data('clif_labs')\n",
    "meds = pyCLIF.load_data('clif_medication_admin_continuous')\n",
    "resp_support = pyCLIF.load_data('clif_respiratory_support')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project specific QC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all these tables have the required variables\n",
    "# check variable data types are correct; if not correct them\n",
    "# check the particular categories we want \n",
    "# check that the categories value range is appropriate\n",
    "# check that the tables do not have duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define expected schemas\n",
    "expected_columns_clif_patient = {\n",
    "    'patient_id': 'varchar',\n",
    "    'race_category': 'varchar',\n",
    "    'ethnicity_category': 'varchar',\n",
    "    'sex_category': 'varchar'\n",
    "}\n",
    "\n",
    "expected_columns_clif_hospitalization = {\n",
    "    'patient_id': 'varchar',\n",
    "    'hospitalization_id': 'varchar',\n",
    "    'admission_dttm': 'datetime',\n",
    "    'discharge_dttm': 'datetime',\n",
    "    'age_at_admission': 'int'\n",
    "}\n",
    "\n",
    "expected_categories_clif_vitals = {\n",
    "    'vital_category': ['heart_rate', 'resp_rate', 'sbp', 'dbp', 'map', 'spo2']\n",
    "}\n",
    "\n",
    "# Load data\n",
    "df_patient = pyCLIF.load_data('clif_patient')\n",
    "df_hospitalization = pyCLIF.load_data('clif_hospitalization')\n",
    "df_vitals = pyCLIF.load_data('clif_vitals')\n",
    "\n",
    "# Perform QC checks\n",
    "qc_report_patient = pyCLIF.qc_check(df_patient, 'clif_patient', expected_columns_clif_patient)\n",
    "qc_report_hospitalization = pyCLIF.qc_check(df_hospitalization, 'clif_hospitalization', expected_columns_clif_hospitalization)\n",
    "qc_report_vitals = pyCLIF.qc_check(df_vitals, 'clif_vitals', expected_columns={\n",
    "    'hospitalization_id': 'varchar',\n",
    "    'recorded_dttm': 'datetime',\n",
    "    'vital_category': 'varchar',\n",
    "    'vital_value': 'float'\n",
    "}, expected_categories=expected_categories_clif_vitals)\n",
    "\n",
    "# Display QC reports\n",
    "print(qc_report_patient)\n",
    "print(qc_report_hospitalization)\n",
    "print(qc_report_vitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mobilization)",
   "language": "python",
   "name": ".mobilization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
