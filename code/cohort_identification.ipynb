{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eligibility for mobilization: Cohort identification. \n",
    "\n",
    "This script identifies the cohort using CLIF 2.0 tables. \n",
    "\n",
    "Requirements:\n",
    "* Required table filenames should be clif_patient, clif_hospitalization, clif_adt, clif_vitals, clif_labs, clif_medication_admin_continuous, clif_respiratory_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration from config.json\n",
      "{'site_name': 'UCMC', 'tables_path': '/Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19', 'file_type': 'parquet'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import pyCLIF\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required columns and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'device_name',\n",
    "    'device_category',\n",
    "    'mode_name', \n",
    "    'mode_category',\n",
    "    'tracheostomy',\n",
    "    'fio2_set',\n",
    "    'lpm_set',\n",
    "    'resp_rate_set',\n",
    "    'peep_set',\n",
    "    'resp_rate_obs',\n",
    "    'tidal_volume_set'\n",
    "]\n",
    "\n",
    "vitals_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'vital_category',\n",
    "    'vital_value'\n",
    "]\n",
    "vitals_of_interest = ['heart_rate', 'resp_rate', 'sbp', 'dbp', 'map', 'resp_rate', 'spo2']\n",
    "\n",
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['lactate']\n",
    "\n",
    "meds_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'admin_dttm',\n",
    "    'med_name',\n",
    "    'med_category',\n",
    "    'med_dose',\n",
    "    'med_dose_unit'\n",
    "]\n",
    "meds_of_interest = [\n",
    "    'norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin',\n",
    "    'dopamine', 'angiotensin', 'nicardipine', 'nitroprusside',\n",
    "    'clevidipine', 'cisatracurium'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_patient.parquet\n",
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_hospitalization.parquet\n"
     ]
    }
   ],
   "source": [
    "patient = pyCLIF.load_data('clif_patient')\n",
    "hospitalization = pyCLIF.load_data('clif_hospitalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all _dttm variables to the same format\n",
    "patient = pyCLIF.standardize_datetime(patient)\n",
    "hospitalization = pyCLIF.standardize_datetime(hospitalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame: patient\n",
      "No duplicates found based on columns: ['patient_id'].\n",
      "Processing DataFrame: hospitalization\n",
      "No duplicates found based on columns: ['hospitalization_id'].\n"
     ]
    }
   ],
   "source": [
    "patient = pyCLIF.remove_duplicates(patient, ['patient_id'], 'patient')\n",
    "hospitalization = pyCLIF.remove_duplicates(hospitalization, ['hospitalization_id'], 'hospitalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of unique encounters in the data: 448402\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Number of unique encounters in the data: {pyCLIF.count_unique_encounters(hospitalization, 'hospitalization_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inclusion Criteria:\n",
    "\n",
    "* Filter Admissions for March 1, 2020 - March 31, 2022\n",
    "* Encounters receiving invasive mechanical ventilation during this period\n",
    "\n",
    "### Exclusion criteria:\n",
    "\n",
    "1. Encounters that were on vent for less than 2 hours\n",
    "2. Encounters that were on trach in the first 72 hours \n",
    "3. Encounters that received Cisatracurium for 4 hours or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique encounters after filtering by date and age: 265523\n"
     ]
    }
   ],
   "source": [
    "cohort = hospitalization[\n",
    "    (hospitalization['admission_dttm'] >= '2018-03-01') &\n",
    "    (hospitalization['admission_dttm'] <= '2023-03-31') &\n",
    "    (hospitalization['age_at_admission'] >= 18)\n",
    "].reset_index(drop=True)[['hospitalization_id']].drop_duplicates()\n",
    "\n",
    "cohort_ids = cohort['hospitalization_id'].unique().tolist()\n",
    "print(f\"Number of unique encounters after filtering by date and age:\", cohort['hospitalization_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_respiratory_support.parquet\n"
     ]
    }
   ],
   "source": [
    "# Import clif respiratory table for this cohort\n",
    "rst_filters = {\n",
    "    'hospitalization_id': cohort_ids\n",
    "}\n",
    "resp_support_raw = pyCLIF.load_data('clif_respiratory_support', columns=rst_required_columns, filters=rst_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rst = resp_support_raw[resp_support_raw['hospitalization_id'] == '11633026']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_support = resp_support_raw.copy()\n",
    "resp_support['recorded_dttm'] = pd.to_datetime(resp_support['recorded_dttm'])\n",
    "resp_support['device_category'] = resp_support['device_category'].str.lower()\n",
    "resp_support['mode_category'] = resp_support['mode_category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating waterfall processing...\n",
      "Fixing out-of-range values for 'fio2_set', 'peep_set', and 'resp_rate_set'...\n",
      "Creating recorded_date and recorded_hour...\n",
      "Sorting data by 'hospitalization_id' and 'recorded_dttm'...\n",
      "Fixing missing 'device_category' and 'device_name' based on 'mode_category'...\n",
      "Fixing 'device_category' and 'device_name' based on neighboring records...\n",
      "Handling duplicates and removing rows with all key variables missing...\n",
      "Filling forward 'device_category' within each hospitalization...\n",
      "Creating 'device_cat_id' to track changes in 'device_category'...\n",
      "Filling 'device_name' within each 'device_cat_id'...\n",
      "Creating 'device_id' to track changes in 'device_name'...\n",
      "Filling 'mode_category' within each 'device_id'...\n",
      "Creating 'mode_cat_id' to track changes in 'mode_category'...\n",
      "Filling 'mode_name' within each 'mode_cat_id'...\n",
      "Creating 'mode_name_id' to track changes in 'mode_name'...\n",
      "Adjusting 'fio2_set' for 'room air' device_category...\n",
      "Adjusting 'mode_category' for 't-piece' devices...\n",
      "Filling remaining variables within each 'mode_name_id'...\n",
      "Filling 'tracheostomy' forward within each hospitalization...\n",
      "Removing duplicates...\n",
      "Waterfall processing completed.\n"
     ]
    }
   ],
   "source": [
    "# Apply Nick's Waterfall fill logic for respiratory support table\n",
    "# This can take time- 1- 12 mins depending on data size\n",
    "processed_resp_support = pyCLIF.process_resp_support(resp_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame: processed_resp_support\n",
      "No duplicates found based on columns: ['hospitalization_id', 'recorded_dttm', 'device_category', 'mode_category'].\n"
     ]
    }
   ],
   "source": [
    "processed_resp_support = pyCLIF.remove_duplicates(processed_resp_support, \n",
    "                                        ['hospitalization_id', 'recorded_dttm',\n",
    "                                         'device_category','mode_category' ], \n",
    "                                         'processed_resp_support')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIO2_SET MEAN 0.48376030677256426\n",
      "Number of unique encounters after filtering for ventilator usage: 2755\n"
     ]
    }
   ],
   "source": [
    "# Identify the cohort on invasive mechanical ventilation \n",
    "columns_to_keep = [\n",
    "    'hospitalization_id', 'recorded_dttm', 'device_name','device_category',\n",
    "    'mode_name', 'mode_category' , 'tracheostomy',\n",
    "    'fio2_set', 'lpm_set', 'peep_set', \n",
    "    'resp_rate_obs', 'resp_rate_set'\n",
    "]\n",
    "\n",
    "ventilator_usage = processed_resp_support[processed_resp_support['device_category'].str.contains(\"imv\", case=False, na=False)]\n",
    "cohort_on_vent = ventilator_usage.merge(cohort, on='hospitalization_id', how='left')\n",
    "cohort_ids = cohort_on_vent['hospitalization_id'].unique().tolist()\n",
    "\n",
    "cohort_on_vent = cohort_on_vent[columns_to_keep]\n",
    "cohort_on_vent['on_vent'] = cohort_on_vent['device_category'].str.contains(\"imv\", case=False, na=False).astype(int)\n",
    "cohort_on_vent = cohort_on_vent.sort_values(by=['hospitalization_id', 'recorded_dttm'])\n",
    "cohort_on_vent = cohort_on_vent[cohort_on_vent['on_vent'] == 1]\n",
    "\n",
    "cohort_on_vent.loc[:, 'recorded_dttm'] = pd.to_datetime(cohort_on_vent['recorded_dttm'])\n",
    "# Apply thresholds and replace values outside these with NaN using .loc[]\n",
    "# UPDATE THIS TO USE CSV / JSON FROM OUTLIER DIRECTORY\n",
    "# cohort_on_vent.loc[:, 'fio2_set'] = cohort_on_vent['fio2_set'].where(cohort_on_vent['fio2_set'].between(0.21, 1, inclusive='both'), np.nan)\n",
    "# Calculate the mean of 'fio2_set', excluding NaN values\n",
    "fio2_mean = cohort_on_vent['fio2_set'].mean(skipna=True)\n",
    "print(\"FIO2_SET MEAN\", fio2_mean)\n",
    "# If the mean is greater than 1, divide 'fio2_set' by 100\n",
    "if fio2_mean > 1:\n",
    "    # Only divide values greater than 1 to avoid re-dividing already correct values\n",
    "    print(\"Updated fio2_set to be between 0.21 and 1\")\n",
    "    cohort_on_vent.loc[cohort_on_vent['fio2_set'] > 1, 'fio2_set'] = \\\n",
    "        cohort_on_vent.loc[cohort_on_vent['fio2_set'] > 1, 'fio2_set'] / 100\n",
    "\n",
    "cohort_on_vent.loc[:, 'fio2_set'] = cohort_on_vent['fio2_set'].where(cohort_on_vent['fio2_set'].between(0.21, 1, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'resp_rate_set'] = cohort_on_vent['resp_rate_set'].where(cohort_on_vent['resp_rate_set'].between(0, 60, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'peep_set'] = cohort_on_vent['peep_set'].where(cohort_on_vent['peep_set'].between(0, 50, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'resp_rate_obs'] = cohort_on_vent['resp_rate_obs'].where(cohort_on_vent['resp_rate_obs'].between(0, 100, inclusive='both'), np.nan)\n",
    "cohort_on_vent.loc[:, 'lpm_set'] = cohort_on_vent['lpm_set'].where(cohort_on_vent['lpm_set'].between(0, 60, inclusive='both'), np.nan)\n",
    "\n",
    "cohort_on_vent['recorded_date'] = cohort_on_vent['recorded_dttm'].dt.date\n",
    "cohort_on_vent['recorded_hour'] = cohort_on_vent['recorded_dttm'].dt.hour\n",
    "\n",
    "print(f\"Number of unique encounters after filtering for ventilator usage: {cohort_on_vent['hospitalization_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_start_end = cohort_on_vent.groupby('hospitalization_id').agg(\n",
    "    vent_start_time=('recorded_dttm', 'min'),\n",
    "    vent_end_time=('recorded_dttm', 'max')\n",
    ").reset_index()\n",
    "# Exclude encounters that were on vent for less than 2 hours\n",
    "vent_start_end = vent_start_end[vent_start_end['vent_start_time'] != vent_start_end['vent_end_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_vitals.parquet\n"
     ]
    }
   ],
   "source": [
    "# import required vitals\n",
    "vitals_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'vital_category': vitals_of_interest\n",
    "}\n",
    "vitals = pyCLIF.load_data('clif_vitals', columns=vitals_required_columns, filters=vitals_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique encounters in vitals 2745\n"
     ]
    }
   ],
   "source": [
    "# Get first_vital_dttm and last_vital_dttm for each hospitalization_id \n",
    "# We use this as proxy for admission and discharge dttm\n",
    "vital_dttm_bounds = vitals.groupby('hospitalization_id')['recorded_dttm'].agg(['min', 'max']).reset_index()\n",
    "vital_dttm_bounds.columns = ['hospitalization_id', 'first_vital_dttm', 'last_vital_dttm']\n",
    "print(\"unique encounters in vitals\", pyCLIF.count_unique_encounters(vital_dttm_bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly sequence for the cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique encounters in resp filtered 2638\n"
     ]
    }
   ],
   "source": [
    "final_cohort = vent_start_end.merge(vital_dttm_bounds, on='hospitalization_id', how='inner')\n",
    "print(\"unique encounters in resp filtered\", pyCLIF.count_unique_encounters(final_cohort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases where last vital dttm is before vent_start time: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalization_id</th>\n",
       "      <th>vent_start_time</th>\n",
       "      <th>vent_end_time</th>\n",
       "      <th>first_vital_dttm</th>\n",
       "      <th>last_vital_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hospitalization_id, vent_start_time, vent_end_time, first_vital_dttm, last_vital_dttm]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check - last recorded vital shouldn't be less than vent start time\n",
    "cases_before_vent_start = final_cohort[final_cohort['last_vital_dttm'] < final_cohort['vent_start_time']]\n",
    "print(\"Cases where last vital dttm is before vent_start time:\", len(cases_before_vent_start))\n",
    "cases_before_vent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/jxkvz04s3q55f82vwjbj_5w80000gq/T/ipykernel_2680/2652486078.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  hour_sequence = final_cohort.groupby('hospitalization_id')\\\n"
     ]
    }
   ],
   "source": [
    "# Function to generate hourly sequence for each group (hospitalization_id)\n",
    "def generate_hourly_sequence(group):\n",
    "    # Get the vent start time and discharge time\n",
    "    start_time = group['vent_start_time'].iloc[0]\n",
    "    end_time = group['last_vital_dttm'].iloc[0]\n",
    "    \n",
    "    # Generate the sequence of hourly timestamps\n",
    "    hourly_timestamps = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "    \n",
    "    # Create a new DataFrame for this sequence\n",
    "    return pd.DataFrame({\n",
    "        'hospitalization_id': group['hospitalization_id'].iloc[0],\n",
    "        'recorded_dttm': hourly_timestamps\n",
    "    })\n",
    "\n",
    "# Apply the function to each group and concatenate the results\n",
    "hour_sequence = final_cohort.groupby('hospitalization_id')\\\n",
    "    .apply(generate_hourly_sequence)\\\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "# Add `recorded_date` and `recorded_hour` columns\n",
    "# Convert recorded_dttm to datetime sanity check\n",
    "hour_sequence['recorded_dttm'] = pd.to_datetime(hour_sequence['recorded_dttm'])\n",
    "hour_sequence['recorded_date'] = hour_sequence['recorded_dttm'].dt.date\n",
    "hour_sequence['recorded_hour'] = hour_sequence['recorded_dttm'].dt.hour\n",
    "hour_sequence['time_from_vent'] = hour_sequence.groupby('hospitalization_id').cumcount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Respiratory support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_vent_df = cohort_on_vent.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour']).agg(\n",
    "    min_resp_rate_obs=pd.NamedAgg(column='resp_rate_obs', aggfunc='min'),\n",
    "    min_lpm_set=pd.NamedAgg(column='lpm_set', aggfunc='min'),\n",
    "    min_fio2_set=pd.NamedAgg(column='fio2_set', aggfunc='min'),\n",
    "    min_peep_set=pd.NamedAgg(column='peep_set', aggfunc='min'),\n",
    "    max_resp_rate_obs=pd.NamedAgg(column='resp_rate_obs', aggfunc='max'),\n",
    "    max_lpm_set=pd.NamedAgg(column='lpm_set', aggfunc='max'),\n",
    "    max_fio2_set=pd.NamedAgg(column='fio2_set', aggfunc='max'),\n",
    "    max_peep_set=pd.NamedAgg(column='peep_set', aggfunc='max'),\n",
    "    hourly_trach=pd.NamedAgg(column='tracheostomy', aggfunc=lambda x: 1 if x.max() == 1 else 0),\n",
    "    hourly_on_vent=pd.NamedAgg(column='on_vent', aggfunc=lambda x: 1 if x.max() == 1 else 0)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique encounters in merged df 2638\n"
     ]
    }
   ],
   "source": [
    "# Merge hourly_vent_df with hour_sequence on hospitalization_id, recorded_date, and recorded_hour\n",
    "final_df = pd.merge(hour_sequence, hourly_vent_df, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                     how='left')\n",
    "print(\"unique encounters in merged df\", pyCLIF.count_unique_encounters(final_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals['recorded_dttm'] = pd.to_datetime(vitals['recorded_dttm'])\n",
    "vitals['recorded_hour'] = vitals['recorded_dttm'].dt.hour\n",
    "vitals['recorded_date'] = vitals['recorded_dttm'].dt.date\n",
    "\n",
    "vitals_min_max = vitals.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour', 'vital_category']).agg(\n",
    "    min=pd.NamedAgg(column='vital_value', aggfunc='min'),\n",
    "    max=pd.NamedAgg(column='vital_value', aggfunc='max')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the table to reshape it\n",
    "vitals_pivot = vitals_min_max.pivot_table(\n",
    "    index=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    columns='vital_category',\n",
    "    values=['min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the column multi-index after pivot\n",
    "vitals_pivot.columns = ['_'.join(col).strip() if type(col) is tuple else col for col in vitals_pivot.columns]\n",
    "# Remove trailing underscores\n",
    "vitals_pivot.columns = [col.rstrip('_') for col in vitals_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hospitalization_id', 'recorded_date', 'recorded_hour', 'max_dbp',\n",
      "       'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp',\n",
      "       'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vitals_pivot.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalization_id</th>\n",
       "      <th>recorded_dttm</th>\n",
       "      <th>recorded_date</th>\n",
       "      <th>recorded_hour</th>\n",
       "      <th>time_from_vent</th>\n",
       "      <th>min_resp_rate_obs</th>\n",
       "      <th>min_lpm_set</th>\n",
       "      <th>min_fio2_set</th>\n",
       "      <th>min_peep_set</th>\n",
       "      <th>max_resp_rate_obs</th>\n",
       "      <th>...</th>\n",
       "      <th>max_dbp</th>\n",
       "      <th>max_heart_rate</th>\n",
       "      <th>max_map</th>\n",
       "      <th>max_sbp</th>\n",
       "      <th>max_spo2</th>\n",
       "      <th>min_dbp</th>\n",
       "      <th>min_heart_rate</th>\n",
       "      <th>min_map</th>\n",
       "      <th>min_sbp</th>\n",
       "      <th>min_spo2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000314</td>\n",
       "      <td>2020-07-01 23:30:00-05:00</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000314</td>\n",
       "      <td>2020-07-02 00:30:00-05:00</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000314</td>\n",
       "      <td>2020-07-02 01:30:00-05:00</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000314</td>\n",
       "      <td>2020-07-02 02:30:00-05:00</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000314</td>\n",
       "      <td>2020-07-02 03:30:00-05:00</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospitalization_id             recorded_dttm recorded_date  recorded_hour  \\\n",
       "0            1000314 2020-07-01 23:30:00-05:00    2020-07-01             23   \n",
       "1            1000314 2020-07-02 00:30:00-05:00    2020-07-02              0   \n",
       "2            1000314 2020-07-02 01:30:00-05:00    2020-07-02              1   \n",
       "3            1000314 2020-07-02 02:30:00-05:00    2020-07-02              2   \n",
       "4            1000314 2020-07-02 03:30:00-05:00    2020-07-02              3   \n",
       "\n",
       "   time_from_vent  min_resp_rate_obs  min_lpm_set  min_fio2_set  min_peep_set  \\\n",
       "0               0               20.0          NaN           1.0           5.0   \n",
       "1               1               20.0          NaN           0.5           5.0   \n",
       "2               2               20.0          NaN           0.5           5.0   \n",
       "3               3                NaN          NaN           NaN           NaN   \n",
       "4               4               20.0          NaN           0.6           5.0   \n",
       "\n",
       "   max_resp_rate_obs  ...  max_dbp  max_heart_rate  max_map  max_sbp  \\\n",
       "0               20.0  ...    112.0           126.0     95.0    163.0   \n",
       "1               20.0  ...     59.0           114.0     79.0    135.0   \n",
       "2               20.0  ...     57.0           109.0     76.0    120.0   \n",
       "3                NaN  ...     48.0            99.0     64.0    108.0   \n",
       "4               27.0  ...     53.0            92.0     68.0    103.0   \n",
       "\n",
       "   max_spo2  min_dbp  min_heart_rate  min_map  min_sbp  min_spo2  \n",
       "0     100.0     58.0            66.0     80.0    131.0      99.0  \n",
       "1      98.0     59.0           114.0     79.0    135.0      98.0  \n",
       "2      95.0     57.0           109.0     76.0    120.0      95.0  \n",
       "3      92.0     48.0            99.0     64.0    108.0      92.0  \n",
       "4      95.0     53.0            92.0     68.0    103.0      92.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge vitals with the blocked resp support data\n",
    "final_df = pd.merge(final_df, vitals_pivot, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                   how='left')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospitalization_id', 'recorded_dttm', 'recorded_date', 'recorded_hour',\n",
       "       'time_from_vent', 'min_resp_rate_obs', 'min_lpm_set', 'min_fio2_set',\n",
       "       'min_peep_set', 'max_resp_rate_obs', 'max_lpm_set', 'max_fio2_set',\n",
       "       'max_peep_set', 'hourly_trach', 'hourly_on_vent', 'max_dbp',\n",
       "       'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp',\n",
       "       'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DataFrame: final_df\n",
      "No duplicates found based on columns: ['hospitalization_id', 'recorded_dttm', 'recorded_date', 'recorded_hour', 'time_from_vent', 'min_resp_rate_obs', 'min_lpm_set', 'min_fio2_set', 'min_peep_set', 'max_resp_rate_obs', 'max_lpm_set', 'max_fio2_set', 'max_peep_set', 'hourly_trach', 'hourly_on_vent', 'max_dbp', 'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp', 'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2'].\n"
     ]
    }
   ],
   "source": [
    "checkpoint_vitals = pyCLIF.remove_duplicates(final_df, [\n",
    "    'hospitalization_id', 'recorded_dttm', 'recorded_date', 'recorded_hour',\n",
    "       'time_from_vent', 'min_resp_rate_obs', 'min_lpm_set', 'min_fio2_set',\n",
    "       'min_peep_set', 'max_resp_rate_obs', 'max_lpm_set', 'max_fio2_set',\n",
    "       'max_peep_set', 'hourly_trach', 'hourly_on_vent', 'max_dbp',\n",
    "       'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp',\n",
    "       'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2'\n",
    "], 'final_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Lab\n",
    "\n",
    "Get most recent lactate defined as closest lab result time to the start of first intubation event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_labs.parquet\n",
      "unique encounters in labs 2686\n"
     ]
    }
   ],
   "source": [
    "# Import clif continuous meds and clif labs table for the cohort on vent during the required time period\n",
    "labs_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'lab_category': labs_of_interest\n",
    "}\n",
    "labs = pyCLIF.load_data('clif_labs', columns=labs_required_columns, filters=labs_filters)\n",
    "print(\"unique encounters in labs\", pyCLIF.count_unique_encounters(labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs['lab_result_dttm'] = pd.to_datetime(labs['lab_result_dttm'])\n",
    "labs['recorded_hour'] = labs['lab_result_dttm'].dt.hour\n",
    "labs['recorded_date'] = labs['lab_result_dttm'].dt.date\n",
    "\n",
    "lactate_df = pd.merge(labs, vent_start_end, on='hospitalization_id', how='left')\n",
    "lactate_df['time_since_vent_start_hours'] = (\n",
    "    (lactate_df['lab_result_dttm'] - lactate_df['vent_start_time']).dt.total_seconds() / 3600\n",
    ")\n",
    "\n",
    "# Calculate the absolute time difference between lab_result_dttm and vent_start_time in hours\n",
    "lactate_df['time_diff_hours'] = abs((lactate_df['lab_result_dttm'] - lactate_df['vent_start_time']).dt.total_seconds() / 3600)\n",
    "\n",
    "# Filter for observations within the first 72 hours since vent_start_time\n",
    "# lactate_df = lactate_df[(lactate_df['time_since_vent_start_hours'] >= 0) & \n",
    "#                         (lactate_df['time_since_vent_start_hours'] <= 72)]\n",
    "\n",
    "# Sort by hospitalization_id, recorded_hour, and time_diff_hours to find the closest measurement to vent_start_time\n",
    "lactate_df = lactate_df.sort_values(by=['hospitalization_id', 'recorded_date', 'recorded_hour', 'time_diff_hours'])\n",
    "\n",
    "# Group by hospitalization_id and recorded_hour, and get the first row in each group (which is the closest measurement)\n",
    "# closest lactate measurement is defined as closest to the vent_start_time in that hour. \n",
    "closest_lactate_df = lactate_df.groupby(['hospitalization_id', 'recorded_date','recorded_hour']).first().reset_index()\n",
    "\n",
    "labs_final = closest_lactate_df[['hospitalization_id', 'recorded_date', 'recorded_hour', 'lab_value_numeric']].copy()\n",
    "\n",
    "# Rename the 'lab_value_numeric' column to 'lactate'\n",
    "labs_final = labs_final.rename(columns={'lab_value_numeric': 'lactate'})\n",
    "\n",
    "final_df = pd.merge(final_df, labs_final, on=['hospitalization_id', 'recorded_date', 'recorded_hour'], \n",
    "                   how='left')\n",
    "\n",
    "# checkpoint_labs = pyCLIF.remove_duplicates(final_df, \n",
    "#                                            ['hospitalization_id', 'recorded_dttm', 'recorded_date', 'recorded_hour',\n",
    "#        'time_from_vent', 'min_resp_rate_obs', 'min_lpm_set', 'min_fio2_set',\n",
    "#        'min_peep_set', 'max_resp_rate_obs', 'max_lpm_set', 'max_fio2_set',\n",
    "#        'max_peep_set', 'hourly_trach', 'hourly_on_vent', 'max_dbp',\n",
    "#        'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp',\n",
    "#        'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2', 'lactate'], 'final_df')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospitalization_id', 'recorded_dttm', 'recorded_date', 'recorded_hour',\n",
       "       'time_from_vent', 'min_resp_rate_obs', 'min_lpm_set', 'min_fio2_set',\n",
       "       'min_peep_set', 'max_resp_rate_obs', 'max_lpm_set', 'max_fio2_set',\n",
       "       'max_peep_set', 'hourly_trach', 'hourly_on_vent', 'max_dbp',\n",
       "       'max_heart_rate', 'max_map', 'max_sbp', 'max_spo2', 'min_dbp',\n",
       "       'min_heart_rate', 'min_map', 'min_sbp', 'min_spo2', 'lactate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hourly Meds\n",
    "\n",
    "* Exclude encounters that received Cisatracurium for 4 hours or more\n",
    "* Calculate NE equivalent levels using \"norepinephrine\", \"epinephrine\", \"phenylephrine\", \"vasopressin\", \"dopamine\",  \"angiotensin\"\n",
    "* Create flags for \"nicardipine\", \"nitroprusside\", \"clevidipine\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/kavenchhikara/Desktop/CLIF/CLIF-UCMC/rclif/c19/clif_medication_admin_continuous.parquet\n",
      "unique encounters in meds 15077\n"
     ]
    }
   ],
   "source": [
    "# Import clif continuous meds for the cohort on vent during the required time period\n",
    "meds_filters = {\n",
    "    'hospitalization_id': cohort_ids,\n",
    "    'med_category': meds_of_interest\n",
    "}\n",
    "meds = pyCLIF.load_data('clif_medication_admin_continuous', columns=meds_required_columns, filters=meds_filters)\n",
    "print(\"unique encounters in meds\", pyCLIF.count_unique_encounters(meds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds['admin_dttm'] = pd.to_datetime(meds['admin_dttm'], format='%Y-%m-%d %H:%M:%S')\n",
    "meds['med_dose'] = pd.to_numeric(meds['med_dose'], errors='coerce')\n",
    "# Create 'date' and 'hour_of_day' columns\n",
    "meds['recorded_date'] = meds['admin_dttm'].dt.date\n",
    "meds['recorded_hour'] = meds['admin_dttm'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "med_category\n",
       "norepinephrine    226364\n",
       "vasopressin        77774\n",
       "phenylephrine      62007\n",
       "dopamine           39412\n",
       "epinephrine        33962\n",
       "clevidipine        24971\n",
       "angiotensin        14239\n",
       "cisatracurium      12093\n",
       "nicardipine         5569\n",
       "nitroprusside        546\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meds.value_counts('med_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle norepinephrine equivalent calculations and exclusion based on cisatracurium\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospitalization_id', 'admin_dttm', 'med_name', 'med_category',\n",
       "       'med_dose', 'med_dose_unit', 'recorded_date', 'recorded_hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude encounters that are on cisatracurium for more than 4 hours in the first 72 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zj/jxkvz04s3q55f82vwjbj_5w80000gq/T/ipykernel_2680/21984481.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cis_periods = cisatracurium_filtered.groupby('hospitalization_id').apply(identify_continuous_periods).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'admin_dttm' is in datetime format\n",
    "cisatracurium_filtered = meds[meds['med_category'].str.contains(\"cisatracurium\", case=False, na=False)].drop_duplicates()\n",
    "\n",
    "# Sort by 'hospitalization_id' and 'admin_dttm'\n",
    "cisatracurium_filtered = cisatracurium_filtered.sort_values(['hospitalization_id', 'admin_dttm'])\n",
    "\n",
    "# Define the maximum allowed gap between doses (e.g., 1 hour)\n",
    "max_gap = pd.Timedelta(hours=1)\n",
    "\n",
    "# Function to identify continuous periods\n",
    "def identify_continuous_periods(group):\n",
    "    group = group.copy()\n",
    "    group['time_diff'] = group['admin_dttm'].diff()\n",
    "    group['new_period'] = (group['time_diff'] > max_gap) | (group['time_diff'].isna())\n",
    "    group['period_id'] = group['new_period'].cumsum()\n",
    "    return group\n",
    "\n",
    "# Apply the function to each 'hospitalization_id'\n",
    "cis_periods = cisatracurium_filtered.groupby('hospitalization_id').apply(identify_continuous_periods).reset_index(drop=True)\n",
    "\n",
    "# Calculate the duration of each continuous period\n",
    "period_durations = cis_periods.groupby(['hospitalization_id', 'period_id']).agg(\n",
    "    period_start=('admin_dttm', 'min'),\n",
    "    period_end=('admin_dttm', 'max')\n",
    ").reset_index()\n",
    "\n",
    "period_durations['period_duration'] = (\n",
    "    period_durations['period_end'] - period_durations['period_start']\n",
    ").dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "# Identify patients with any continuous period >= 4 hours\n",
    "cis_flag_df = period_durations.groupby('hospitalization_id').agg(\n",
    "    max_period_duration=('period_duration', 'max')\n",
    ").reset_index()\n",
    "\n",
    "cis_flag_df['cis_flag'] = (cis_flag_df['max_period_duration'] >= 4).astype(int)\n",
    "\n",
    "# Merge 'cis_flag' back to your main DataFrame (e.g., 'vent_start_end')\n",
    "vent_start_end = vent_start_end.merge(\n",
    "    cis_flag_df[['hospitalization_id', 'cis_flag']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values in 'cis_flag' with 0 (patients who didn't meet the criteria)\n",
    "vent_start_end['cis_flag'] = vent_start_end['cis_flag'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cisatracurium administrations\n",
    "cisatracurium_filtered = meds[meds['med_category'].str.contains(\"cisatracurium\", case=False, na=False)].drop_duplicates()\n",
    "cisatracurium_filtered = cisatracurium_filtered.sort_values(['hospitalization_id', 'admin_dttm'])\n",
    "\n",
    "# Merge with vent_start_end to get vent_start_time\n",
    "cisatracurium_filtered = cisatracurium_filtered.merge(\n",
    "    vent_start_end[['hospitalization_id', 'vent_start_time']], \n",
    "    on='hospitalization_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Filter administrations that occurred after vent_start_time\n",
    "cisatracurium_filtered = cisatracurium_filtered[\n",
    "    cisatracurium_filtered['admin_dttm'] >= cisatracurium_filtered['vent_start_time']\n",
    "]\n",
    "\n",
    "# Group by 'hospitalization_id' and calculate duration\n",
    "cis_duration = cisatracurium_filtered.groupby('hospitalization_id').agg(\n",
    "    first_admin=('admin_dttm', 'min'),\n",
    "    last_admin=('admin_dttm', 'max'),\n",
    "    vent_start_time=('vent_start_time', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the duration between first and last cisatracurium administration\n",
    "cis_duration['cis_admin_duration'] = (\n",
    "    cis_duration['last_admin'] - cis_duration['first_admin']\n",
    ").dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "# Check for continuous administration of cisatracurium for 4 hours or more\n",
    "cis_duration['cis_flag'] = cis_duration.apply(\n",
    "    lambda row: 1 if (row['last_admin'] - row['first_admin']).total_seconds() / 3600 >= 4 else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cisatracurium_filtered = meds[meds['med_category'].str.contains(\"cisatracurium\", case=False, na=False)].drop_duplicates().sort_values('hospitalization_id')\n",
    "cisatracurium_filtered = cisatracurium_filtered.merge(vent_start_end, on='hospitalization_id', how='left')\n",
    "cisatracurium_filtered['duration'] = (cisatracurium_filtered['admin_dttm'] - cisatracurium_filtered['vent_start_time']).dt.total_seconds() / 3600\n",
    "cisatracurium_filtered['cis_flag'] = cisatracurium_filtered['duration'].apply(lambda x: 1 if x > 4 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_list = [\n",
    "    \"norepinephrine\", \"epinephrine\", \"phenylephrine\", \n",
    "    \"vasopressin\", \"dopamine\",  \n",
    "    \"angiotensin\", \"cisatracurium\"\n",
    "]\n",
    "\n",
    "#  Filter for Cisatracurium from the meds table - entire dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to aggregate min and max doses by medication and hour\n",
    "pivoted_med_df = meds_filtered.pivot_table(\n",
    "    index=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    columns='med_category',\n",
    "    values='med_dose',\n",
    "    aggfunc=['min', 'max']\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "pivoted_med_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in pivoted_med_df.columns]\n",
    "# Remove trailing underscores\n",
    "pivoted_med_df.columns = [col.rstrip('_') for col in pivoted_med_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_meds_list = [\n",
    "    \"nicardipine\", \"nitroprusside\", \"clevidipine\"\n",
    "]\n",
    "\n",
    "# Filter meds_filtered for the medications in red_meds_list\n",
    "red_meds_df = meds[meds['med_category'].isin(red_meds_list)].copy()\n",
    "\n",
    "# Create a flag for each medication in red_meds_list\n",
    "for med in red_meds_list:\n",
    "    # Create a flag that is 1 if the medication was administered in that hour, 0 otherwise\n",
    "    red_meds_df[med + '_flag'] = np.where(red_meds_df['med_category'] == med, 1, 0).astype(int)\n",
    "\n",
    "# Aggregate to get the maximum value for each flag (per hospitalization_id, recorded_date, recorded_hour)\n",
    "# This ensures that if the medication was administered even once in the hour, the flag is 1\n",
    "red_meds_flags = red_meds_df.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour']).agg(\n",
    "    {med + '_flag': 'max' for med in red_meds_list}\n",
    ").reset_index()\n",
    "\n",
    "#  combine all flags into a single 'red_meds_flag', you can do so like this:\n",
    "red_meds_flags['red_meds_flag'] = red_meds_flags[[med + '_flag' for med in red_meds_list]].max(axis=1)\n",
    "\n",
    "# Select the relevant columns\n",
    "red_meds_flags_final = red_meds_flags[[\n",
    "    'hospitalization_id', 'recorded_date', 'recorded_hour',\n",
    "    'nicardipine_flag', 'nitroprusside_flag',\n",
    "    'clevidipine_flag', 'red_meds_flag'\n",
    "]].drop_duplicates(subset=['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "\n",
    "red_meds_flags_final['nicardipine_flag'] = pd.to_numeric(red_meds_flags_final['nicardipine_flag'], errors='coerce').fillna(0).astype(int)\n",
    "red_meds_flags_final['nitroprusside_flag'] = pd.to_numeric(red_meds_flags_final['nitroprusside_flag'], errors='coerce').fillna(0).astype(int)\n",
    "red_meds_flags_final['clevidipine_flag'] = pd.to_numeric(red_meds_flags_final['clevidipine_flag'], errors='coerce').fillna(0).astype(int)\n",
    "red_meds_flags_final['red_meds_flag'] = pd.to_numeric(red_meds_flags_final['red_meds_flag'], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hospitalization_id', 'admin_dttm', 'med_name', 'med_category',\n",
       "       'med_dose', 'med_dose_unit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mobilization)",
   "language": "python",
   "name": ".mobilization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
